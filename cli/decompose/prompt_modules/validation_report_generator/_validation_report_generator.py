import re
from collections.abc import Callable
from typing import Any, TypeVar, final

from mellea import MelleaSession
from mellea.backends.types import ModelOption
from mellea.stdlib.chat import Message

from .._prompt_modules import PromptModule, PromptModuleString
from ._exceptions import BackendGenerationError, TagExtractionError
from ._prompt import get_system_prompt, get_user_prompt

T = TypeVar("T")

RE_VALIDATION_REPORT = re.compile(
    r"<validation_report>(.+?)</validation_report>", flags=re.IGNORECASE | re.DOTALL
)


@final
class _ValidationReportGenerator(PromptModule):
    @staticmethod
    def _default_parser(generated_str: str) -> str:
        r"""Default parser of the `validation_report_generator` module.

        This parser extracts the content inside the <validation_report> tags.

        The expected content is a JSON-like validation report, including:

        - is_valid              (bool, from validation function result)
        - constraint_name       (str, typically a snake_case name)
        - failure_cause         (str | null, generated by an LLM)
        - failure_trackback     (list | null, generated by an LLM)
        - error_type            (str | null, from try/except)
        - error_trackback       (list | null, from try/except traceback parsing)

        Args:
            generated_str (str): The LLM's full output to be parsed.

        Returns:
            str: The extracted validation report schema/template string.

        Raises:
            TagExtractionError: If the <validation_report> tags cannot be found
                or parsed in the generated output.
        """
        validation_report_match = re.search(RE_VALIDATION_REPORT, generated_str)

        validation_report_str: str | None = (
            validation_report_match.group(1).strip()
            if validation_report_match
            else None
        )

        if validation_report_str is None:
            raise TagExtractionError(
                'LLM failed to generate correct tags for extraction: "<validation_report>"'
            )

        return validation_report_str

    def generate(
        self,
        mellea_session: MelleaSession,
        input_str: str | None,
        max_new_tokens: int = 4096,
        parser: Callable[[str], T] = _default_parser,  # type: ignore[assignment]
        # About the mypy ignore above: https://github.com/python/mypy/issues/3737
        **kwargs: dict[str, Any],
    ) -> PromptModuleString[T]:
        """Generates a validation report schema/template for a given constraint.

        This module is used at decomposition time to define *how* validation
        results, errors, and failure explanations should be structured for a
        specific constraint.

        The generated schema describes a "Failure Cause Report" with fields:
        - is_valid: bool
        - constraint_name: str
        - failure_cause: str | null
        - failure_trackback: list[TrackbackEntry] | null
        - error_type: str | null
        - error_trackback: list[TrackbackEntry] | null


        Args:
            mellea_session (MelleaSession): A mellea session with a backend.
            input_str (str): Natural language constraint/requirement for which
                the validation report schema should be designed.
            max_new_tokens (int, optional): Maximum tokens to generate.
                Defaults to 4096.
            parser (Callable[[str], Any], optional): A string parsing function.
                Defaults to `_ValidationReportGenerator._default_parser`.

        Returns:
            PromptModuleString: A `PromptModuleString` containing the raw
            <validation_report> content (usually a JSON-like string), with a
            `.parse()` method that applies the provided parser.
        """
        assert input_str is not None, 'This module requires the "input_str" argument'

        system_prompt = get_system_prompt()
        user_prompt = get_user_prompt(constraint_requirement=input_str)

        action = Message("user", user_prompt)

        try:
            gen_result = mellea_session.act(
                action=action,
                model_options={
                    ModelOption.SYSTEM_PROMPT: system_prompt,
                    ModelOption.TEMPERATURE: 0,
                    ModelOption.MAX_NEW_TOKENS: max_new_tokens,
                },
            ).value
        except Exception as e:
            raise BackendGenerationError(f"LLM generation failed: {e}")

        if gen_result is None:
            raise BackendGenerationError(
                "LLM generation failed: value attribute is None"
            )

        return PromptModuleString(gen_result, parser)


validation_report_generator = _ValidationReportGenerator()
